{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tennis-tracking using Image Processing\n",
    "---\n",
    "- Tracking a ball using tracknet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Importing Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import glob\n",
    "import queue\n",
    "import random\n",
    "import argparse\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from os.path import expanduser\n",
    "from PIL import Image, ImageDraw\n",
    "from keras.utils import plot_model\n",
    "from scipy.spatial import distance as dist\n",
    "from collections import defaultdict, OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Converting the image into ground-truth\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "size = 20\n",
    "#create gussian heatmap \n",
    "def gaussian_kernel(variance):\n",
    "    x, y = np.mgrid[-size:size+1, -size:size+1]\n",
    "    g = np.exp(-(x**2+y**2)/float(2*variance))\n",
    "    return g \n",
    "\n",
    "\n",
    "#make the Gaussian by calling the function\n",
    "variance = 10\n",
    "gaussian_kernel_array = gaussian_kernel(variance)\n",
    "#rescale the value to 0-255\n",
    "gaussian_kernel_array =  gaussian_kernel_array * 255/gaussian_kernel_array[int(len(gaussian_kernel_array)/2)][int(len(gaussian_kernel_array)/2)]\n",
    "#change type as integer\n",
    "gaussian_kernel_array = gaussian_kernel_array.astype(int)\n",
    "\n",
    "#show heatmap \n",
    "plt.imshow(gaussian_kernel_array, cmap=plt.get_cmap('gray'), interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#create the heatmap as ground truth\n",
    "images_path = './Dataset/game1/'\n",
    "dirs = glob.glob(images_path+'Clip*')\n",
    "\n",
    "for index in dirs:\n",
    "        pics = glob.glob(index + \"/*.jpg\")\n",
    "        output_pics_path = images_path+'groundtruth/' + os.path.split(index)[-1]\n",
    "        label_path = index + \"/Label.csv\"\n",
    "        \n",
    "        #check if the path need to be create\n",
    "        if not os.path.exists(output_picgs_path ):\n",
    "            os.makedirs(output_pics_path)\n",
    "\n",
    "        #read csv file\n",
    "        with open(label_path, 'r') as csvfile:\n",
    "            spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "            #skip the headers\n",
    "            next(spamreader, None)  \n",
    "            \n",
    "            for row in spamreader:\n",
    "                    visibility = int(float(row[1]))\n",
    "                    FileName = row[0]\n",
    "                    #if visibility == 0, the heatmap is a black image\n",
    "                    if visibility == 0:\n",
    "                        heatmap = Image.new(\"RGB\", (1280, 720))\n",
    "                        pix = heatmap.load()\n",
    "                        for i in range(1280):\n",
    "                            for j in range(720):\n",
    "                                    pix[i,j] = (0,0,0)\n",
    "                    else:\n",
    "                        x = int(float(row[2]))\n",
    "                        y = int(float(row[3]))\n",
    "                        \n",
    "                        #create a black image\n",
    "                        heatmap = Image.new(\"RGB\", (1280, 720))\n",
    "                        pix = heatmap.load()\n",
    "                        for i in range(1280):\n",
    "                            for j in range(720):\n",
    "                                    pix[i,j] = (0,0,0)\n",
    "                                    \n",
    "                        #copy the heatmap on it\n",
    "                        for i in range(-size,size+1):\n",
    "                            for j in range(-size,size+1):\n",
    "                                    if x+i<1280 and x+i>=0 and y+j<720 and y+j>=0 :\n",
    "                                        temp = gaussian_kernel_array[i+size][j+size]\n",
    "                                        if temp > 0:\n",
    "                                            pix[x+i,y+j] = (temp,temp,temp)\n",
    "                    #save image\n",
    "                    heatmap.save(output_pics_path + \"/\" + FileName.split('.')[-2] + \".png\", \"PNG\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Generating Training image\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 19835 Training images: 13884 Testing images: 5951\n"
     ]
    }
   ],
   "source": [
    "#Output training data name to cvs file for model 1\n",
    "\n",
    "tre_name = \"training_model1.csv\"\n",
    "testing_file_aining_filname = \"testing_model1.csv\"\n",
    "visibility_for_testing = []\n",
    "\n",
    "images_path = './Dataset/game1/'\n",
    "directories = []\n",
    "annos_dire = []\n",
    "for i in os.listdir(images_path):\n",
    "    directories.append(os.path.join(images_path,i))\n",
    "    annos_dire.append(os.path.join(images_path+'groundtruth/',i))\n",
    "\n",
    "with open(training_file_name,'w') as file:\n",
    "    for index in range(len(directories)-1):\n",
    "        annos_path = annos_dire[index] + '/'\n",
    "        images_path = directories[index]+'/'\n",
    "\n",
    "        images = glob.glob(images_path + \"*.jpg\")\n",
    "        images.sort()\n",
    "        annotations  = glob.glob(annos_path + \"*.png\")\n",
    "        annotations.sort()\n",
    "        assert len( images ) == len(annotations)\n",
    "        for im , seg in zip(images,annotations):\n",
    "            im = 'r'+str(im)\n",
    "            seg = 'r'+str(seg)\n",
    "            assert(im.split('\\\\')[-1].split('.')[0] == seg.split('\\\\')[-1].split('.')[0])\n",
    "\n",
    "        visibility = {}\n",
    "        with open(images_path + \"Label.csv\", 'r') as csvfile:\n",
    "            spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "            #skip the headers\n",
    "            next(spamreader, None)  \n",
    "            \n",
    "            for row in spamreader:\n",
    "                visibility[row[0]] = row[1]\n",
    "                 \n",
    "        #write all of images path\n",
    "        for i in range(0,len(images)): \n",
    "                file_name = images[i]\n",
    "                file_name = 'r'+str(file_name)\n",
    "                file_name = file_name.split('\\\\')[-1]\n",
    "                #visibility 3 will not be used for training\n",
    "                if visibility[file_name] == '3':\n",
    "                    visibility_for_testing.append(images[i])\n",
    "                    \n",
    "                #check if file image name same as annotation name\n",
    "                assert( images[i].split('/')[-1].split(\".\")[0] ==  annotations[i].split('/')[-1].split(\".\")[0] )\n",
    "                #write all of images path\n",
    "                file.write(images[i] + \",\" + images[i-1] + \",\" + images[i-2] + \",\" + annotations[i] + \"\\n\")\n",
    "file.close()\n",
    "\n",
    "#read all of images path\n",
    "lines = open(training_file_name).read().splitlines()\n",
    "\n",
    "#70% for training, 30% for testing \n",
    "training_images_number = int(len(lines)*0.7)\n",
    "testing_images_number = len(lines) - training_images_number\n",
    "print(\"Total images:\", len(lines), \"Training images:\", training_images_number,\"Testing images:\", testing_images_number)\n",
    "\n",
    "#shuffle the images\n",
    "random.shuffle(lines)\n",
    "#training images\n",
    "with open(training_file_name,'w') as training_file:\n",
    "    training_file.write(\"img, img1, img2, ann\\n\")\n",
    "    #testing images\n",
    "    with open(testing_file_name,'w') as testing_file:\n",
    "        testing_file.write(\"img, img1, img2, ann\\n\")\n",
    "        \n",
    "        #write img, img1, img2, ann to csv file\n",
    "        for i in range(0,len(lines)):\n",
    "            if lines[i] != \"\":\n",
    "                if training_images_number > 0 and lines[i].split(\",\")[0] not in visibility_for_testing :\n",
    "                    training_file.write(lines[i] + \"\\n\")\n",
    "                    training_images_number -=1\n",
    "                else:\n",
    "                    testing_file.write(lines[i] + \"\\n\")\n",
    "training_file.close()\n",
    "testing_file.close()\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Tracknet model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrackNet( n_classes ,  input_height, input_width ): # input_height = 360, input_width = 640\n",
    "\n",
    "    imgs_input = Input(shape=(3,input_height,input_width))\n",
    "\n",
    "    x = Conv2D(64, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(imgs_input)\n",
    "    x = ( Activation('relu'))(x)\n",
    "    x = ( BatchNormalization())(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(x)\n",
    "    x = ( Activation('relu'))(x)\n",
    "    x = ( BatchNormalization())(x)\n",
    "\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), data_format='channels_first' )(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(x)\n",
    "    x = ( Activation('relu'))(x)\n",
    "    x = ( BatchNormalization())(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(x)\n",
    "    x = ( Activation('relu'))(x)\n",
    "    x = ( BatchNormalization())(x)\n",
    "\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), data_format='channels_first' )(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(x)\n",
    "    x = ( Activation('relu'))(x)\n",
    "    x = ( BatchNormalization())(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(x)\n",
    "    x = ( Activation('relu'))(x)\n",
    "    x = ( BatchNormalization())(x)\n",
    "\n",
    "    x = ( Conv2D(512, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first'))(x)\n",
    "    x = ( Activation('relu'))(x)\n",
    "    x = ( BatchNormalization())(x)\n",
    "\n",
    "    x = ( Conv2D( 256, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first'))(x)\n",
    "    x = ( Activation('relu'))(x)\n",
    "    x = ( BatchNormalization())(x)\n",
    "\n",
    "    x = ( Conv2D( 256, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first'))(x)\n",
    "    x = ( Activation('relu'))(x)\n",
    "    x = ( BatchNormalization())(x)\n",
    "\n",
    "    x = ( UpSampling2D( (2,2), data_format='channels_first'))(x)\n",
    "\n",
    "    x = ( Conv2D( 128 , (3, 3), kernel_initializer='random_uniform', padding='same' , data_format='channels_first' ))(x)\n",
    "    x = ( Activation('relu'))(x)\n",
    "    x = ( BatchNormalization())(x)\n",
    "\n",
    "    x = ( Conv2D( 128 , (3, 3), kernel_initializer='random_uniform', padding='same' , data_format='channels_first' ))(x)\n",
    "    x = ( Activation('relu'))(x)\n",
    "    x = ( BatchNormalization())(x)\n",
    "\n",
    "    x = ( UpSampling2D( (2,2), data_format='channels_first'))(x)\n",
    "\n",
    "    x = ( Conv2D( 64 , (3, 3), kernel_initializer='random_uniform', padding='same'  , data_format='channels_first' ))(x)\n",
    "    x = ( Activation('relu'))(x)\n",
    "    x = ( BatchNormalization())(x)\n",
    "\n",
    "    x = ( Conv2D( 64 , (3, 3), kernel_initializer='random_uniform', padding='same'  , data_format='channels_first' ))(x)\n",
    "    x = ( Activation('relu'))(x)\n",
    "    x = ( BatchNormalization())(x)\n",
    "\n",
    "    x =  Conv2D( n_classes , (3, 3) , kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(x)\n",
    "    x = ( Activation('relu'))(x)\n",
    "    x = ( BatchNormalization())(x)\n",
    "\n",
    "    o_shape = Model(imgs_input , x ).output_shape\n",
    "    print(\"layer24 output shape:\", o_shape[1],o_shape[2],o_shape[3])\n",
    "\n",
    "    OutputHeight = o_shape[2]\n",
    "    OutputWidth = o_shape[3]\n",
    "\n",
    "    #reshape the size to (256, 360*640)\n",
    "    x = (Reshape((  -1  , OutputHeight*OutputWidth   )))(x)\n",
    "\n",
    "    #change dimension order to (360*640, 256)\n",
    "    x = (Permute((2, 1)))(x)\n",
    "\n",
    "    gaussian_output = (Activation('softmax'))(x)\n",
    "\n",
    "    model = Model( imgs_input , gaussian_output)\n",
    "    model.outputWidth = OutputWidth\n",
    "    model.outputHeight = OutputHeight\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Getting Data Ready to train\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get inut array\n",
    "def getInputArr( path, width , height):\n",
    "    try:\n",
    "        #read the image\n",
    "        img = cv2.imread(path, 1)\n",
    "        #resize it \n",
    "        img = cv2.resize(img, ( width , height ))\n",
    "        #input must be float type\n",
    "        img = img.astype(np.float32)\n",
    "\n",
    "        #since the odering of TrackNet  is 'channels_first', so we need to change the axis\n",
    "        img = np.rollaxis(img, 2, 0)\n",
    "        return img\n",
    "\n",
    "    except Exception as e:\n",
    "        print(path , e)\n",
    "\n",
    "\n",
    "\n",
    "#get output array\n",
    "def getOutputArr( path , nClasses ,  width , height  ):\n",
    "\n",
    "    seg_labels = np.zeros((  height , width  , nClasses ))\n",
    "    try:\n",
    "        img = cv2.imread(path, 1)\n",
    "        img = cv2.resize(img, ( width , height ))\n",
    "        img = img[:, : , 0]\n",
    "\n",
    "        for c in range(nClasses):\n",
    "            seg_labels[: , : , c ] = (img == c ).astype(int)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    seg_labels = np.reshape(seg_labels, ( width*height , nClasses ))\n",
    "    return seg_labels\n",
    "\n",
    "\n",
    "\n",
    "#read input data and output data\n",
    "def InputOutputGenerator( images_path,  batch_size,  n_classes , input_height , input_width , output_height , output_width ):\n",
    "    #read csv file to 'zipped'\n",
    "    columns = defaultdict(list)\n",
    "    with open(images_path) as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            for (i,v) in enumerate(row):\n",
    "                columns[i].append(v)\n",
    "    zipped = itertools.cycle( zip(columns[0], columns[3]) )\n",
    "\n",
    "    while True:\n",
    "        Input = []\n",
    "        Output = []\n",
    "        #read input&output for each batch\n",
    "        for _ in range( batch_size) :\n",
    "            path, anno = next(zipped)\n",
    "            Input.append( getInputArr(path, input_width , input_height) )\n",
    "            Output.append( getOutputArr( anno , n_classes , output_width , output_height) )\n",
    "        #return input&output\n",
    "        yield np.array(Input) , np.array(Output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Training the model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer24 output shape: 256 360 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cobra\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 516s 3s/step - loss: 0.1632 - accuracy: 0.9709\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 519s 3s/step - loss: 0.0055 - accuracy: 0.9996\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 515s 3s/step - loss: 0.0052 - accuracy: 0.9996\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 517s 3s/step - loss: 0.0050 - accuracy: 0.9996\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 514s 3s/step - loss: 0.0048 - accuracy: 0.9996\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 503s 3s/step - loss: 0.0046 - accuracy: 0.9996\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 425s 2s/step - loss: 0.0037 - accuracy: 0.9996\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 439s 2s/step - loss: 0.0034 - accuracy: 0.9996\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 461s 2s/step - loss: 0.0033 - accuracy: 0.9996\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 417s 2s/step - loss: 0.0034 - accuracy: 0.9996\n"
     ]
    }
   ],
   "source": [
    "training_images_name = 'training_model1.csv'\n",
    "train_batch_size = 2\n",
    "n_classes = 256\n",
    "input_height = 360\n",
    "input_width = 640\n",
    "epochs = 10\n",
    "load_weights = -1\n",
    "step_per_epochs = 200\n",
    "optimizer_name = optimizers.Adadelta(lr=1.0)\n",
    "\n",
    "#load TrackNet model\n",
    "modelTN = TrackNet\n",
    "m = modelTN( n_classes , input_height=input_height, input_width=input_width   )\n",
    "m.compile(loss='categorical_crossentropy', optimizer= optimizer_name, metrics=['accuracy'])\n",
    "\n",
    "#show TrackNet details, save it as TrackNet.png\n",
    "plot_model( m , show_shapes=True , to_file='TrackNet.png')\n",
    "\n",
    "#get TrackNet output height and width\n",
    "model_output_height = m.outputHeight\n",
    "model_output_width = m.outputWidth\n",
    "\n",
    "#creat input data and output data\n",
    "Generator  = InputOutputGenerator( training_images_name,  train_batch_size,  n_classes , input_height , input_width , model_output_height , model_output_width)\n",
    "\n",
    "#start to train the model, and save weights until finish \n",
    "m.fit_generator( Generator, step_per_epochs, epochs )\n",
    "\n",
    "m.save_weights( \"weight.0\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer24 output shape: 256 360 640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2146ec9a8b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weights =  TrackNet\n",
    "new_weights = new_weights( 256 , input_height=360, input_width=640   )\n",
    "\n",
    "new_weights.load_weights('weight.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw Court\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_court(img):\n",
    "\n",
    "    # coordinates found manually\n",
    "    x_1 = 574\n",
    "    y_1 = 300\n",
    "\n",
    "    x_2 = 1338\n",
    "    y_2 = 300\n",
    "\n",
    "    x_3 = 1570\n",
    "    y_3 = 857\n",
    "\n",
    "    x_4 = 358\n",
    "    y_4 = 857\n",
    "\n",
    "    cv2.line(img, (x_1, y_1), (x_2, y_2), (0, 0, 255), 2)\n",
    "    cv2.line(img, (x_2, y_2), (x_3, y_3), (0, 0, 255), 2)\n",
    "    cv2.line(img, (x_3, y_3), (x_4, y_4), (0, 0, 255), 2)\n",
    "    cv2.line(img, (x_4, y_4), (x_1, y_1), (0, 0, 255), 2)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ball Tracking and Player Detection\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_output_layers(net):\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    return output_layers\n",
    "\n",
    "\n",
    "def binary(x):\n",
    "    # transform an image in black and white\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 255\n",
    "\n",
    "\n",
    "def remove_ball_boy(detected_person_img, lower_col, upper_col):\n",
    "    # compute pixel percentage of a range of color (lower_col, upper_col)\n",
    "    # in each box to detect ball boys/girls\n",
    "    mask = cv2.inRange(detected_person_img, lower_col, upper_col)\n",
    "    img = cv2.bitwise_and(detected_person_img, detected_person_img,mask=mask)\n",
    "    func = np.vectorize(binary)\n",
    "    img = func(img).astype(np.uint8)\n",
    "\n",
    "    n_pix = img.shape[0] * img.shape[1]\n",
    "    n_pix_bb = sum(img.flatten()) / img.shape[2] / 255\n",
    "\n",
    "    return n_pix_bb / n_pix\n",
    "\n",
    "\n",
    "def predict_players(outs, LABELS, img, confidence_threshold=0.8):\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    conf_threshold = 0.8\n",
    "    nms_threshold = 0.00000000001\n",
    "    Width = img.shape[1]\n",
    "    Height = img.shape[0]\n",
    "\n",
    "    predicted_players = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            if confidence > conf_threshold and LABELS[class_id] == 'person':\n",
    "                center_x = int(detection[0] * Width)\n",
    "                center_y = int(detection[1] * Height)\n",
    "                w = int(detection[2] * Width)\n",
    "                h = int(detection[3] * Height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                taux = remove_ball_boy(img[y:y + h, x:x + w],(27, 5, 40), (47, 40, 168))\n",
    "\n",
    "                if taux < 0.01:\n",
    "                    class_ids.append(class_id)\n",
    "                    confidences.append(float(confidence))\n",
    "                    boxes.append([x, y, w, h])\n",
    "\n",
    "    # apply non-maxima suppression to suppress weak, overlapping\n",
    "    # bounding boxes\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold,\n",
    "                            nms_threshold)\n",
    "\n",
    "    # ensure at least one detection exists\n",
    "    if len(idxs) > 0:\n",
    "        # loop over the indexes we are keeping\n",
    "        for i in idxs.flatten():\n",
    "            # extract the bounding box coordinates\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "\n",
    "            predicted_players.append((x, y, w, h))\n",
    "\n",
    "    # sometimes, two identical frames remain\n",
    "    predicted_players = list(set(predicted_players))\n",
    "\n",
    "    return predicted_players\n",
    "\n",
    "\n",
    "def update_boxes(box):\n",
    "    x = box[0]\n",
    "    y = box[1]\n",
    "    w = box[2]\n",
    "    h = box[3]\n",
    "    return x, y, x + w, y + h\n",
    "\n",
    "\n",
    "\n",
    "class CentroidTracker():\n",
    "    def __init__(self, maxDisappeared=300):\n",
    "        self.nextObjectID = 0\n",
    "        self.objects = OrderedDict()\n",
    "        self.disappeared = OrderedDict()\n",
    "        self.maxDisappeared = maxDisappeared\n",
    "\n",
    "    def register(self, centroid):\n",
    "        self.objects[self.nextObjectID] = centroid\n",
    "        self.disappeared[self.nextObjectID] = 0\n",
    "        self.nextObjectID += 1\n",
    "\n",
    "    def deregister(self, objectID):\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "\n",
    "    def update(self, rects):\n",
    "        # check to see if the list of input bounding box rectangles\n",
    "        # is empty\n",
    "        if len(rects) == 0:\n",
    "            # loop over any existing tracked objects and mark them\n",
    "            # as disappeared\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID] += 1\n",
    "                # if we have reached a maximum number of consecutive\n",
    "                # frames where a given object has been marked as\n",
    "                # missing, deregister it\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "            # return early as there are no centroids or tracking info\n",
    "            # to update\n",
    "            return self.objects\n",
    "\n",
    "        # initialize an array of input centroids for the current frame\n",
    "        inputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
    "        # loop over the bounding box rectangles\n",
    "        for (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
    "            # use the bounding box coordinates to derive the centroid\n",
    "            cX = int((startX + endX) / 2.0)\n",
    "            cY = int(endY)\n",
    "            inputCentroids[i] = (cX, cY)\n",
    "\n",
    "        if len(self.objects) == 0:\n",
    "            for i in range(0, len(inputCentroids)):\n",
    "                self.register(inputCentroids[i])\n",
    "\n",
    "        else:\n",
    "            # grab the set of object IDs and corresponding centroids\n",
    "            objectIDs = list(self.objects.keys())\n",
    "            objectCentroids = list(self.objects.values())\n",
    "            \n",
    "            D = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
    "\n",
    "            rows = D.min(axis=1).argsort()\n",
    "\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "\n",
    "            usedRows = set()\n",
    "            usedCols = set()\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                if row in usedRows or col in usedCols:\n",
    "                    continue\n",
    "                objectID = objectIDs[row]\n",
    "                self.objects[objectID] = inputCentroids[col]\n",
    "                self.disappeared[objectID] = 0\n",
    "                # indicate that we have examined each of the row and column indexes, respectively\n",
    "                usedRows.add(row)\n",
    "                usedCols.add(col)\n",
    "\n",
    "            # compute both the row and column index we have NOT yet\n",
    "            unusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "            unusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
    "\n",
    "            if D.shape[0] >= D.shape[1]:\n",
    "                # loop over the unused row indexes\n",
    "                for row in unusedRows:\n",
    "                    # grab the object ID for the corresponding row\n",
    "                    # index and increment the disappeared counter\n",
    "                    objectID = objectIDs[row]\n",
    "                    self.disappeared[objectID] += 1\n",
    "                    if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                        self.deregister(objectID)\n",
    "\n",
    "            # otherwise, if the number of input centroids is greater\n",
    "            # than the number of existing object centroids we need to\n",
    "            # register each new input centroid as a trackable object\n",
    "            else:\n",
    "                for col in unusedCols:\n",
    "                    self.register(inputCentroids[col])\n",
    "        # return the set of trackable objects\n",
    "        return self.objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting an Output\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer24 output shape: 256 360 640\n",
      "27 901 648\n",
      "28 894 652\n",
      "29 882 660\n",
      "30 873 664\n",
      "31 873 664\n",
      "32 864 666\n",
      "36 829 702\n",
      "37 827 704\n",
      "38 822 712\n",
      "39 819 724\n",
      "40 807 736\n",
      "41 801 748\n",
      "42 793 763\n",
      "43 793 763\n",
      "46 786 732\n",
      "51 810 642\n",
      "52 816 624\n",
      "53 819 604\n",
      "54 828 582\n",
      "55 828 582\n",
      "56 822 564\n",
      "57 834 552\n",
      "66 858 432\n",
      "67 858 432\n",
      "68 870 426\n",
      "69 865 432\n",
      "70 874 418\n",
      "71 873 406\n",
      "72 879 399\n",
      "73 879 399\n",
      "74 876 390\n",
      "75 883 384\n",
      "76 886 378\n",
      "77 888 370\n",
      "78 894 366\n",
      "79 888 364\n",
      "80 899 359\n",
      "81 894 352\n",
      "82 894 348\n",
      "83 902 344\n",
      "84 903 340\n",
      "85 903 340\n",
      "86 900 321\n",
      "87 909 334\n",
      "88 907 330\n",
      "89 913 324\n",
      "90 913 325\n",
      "91 914 323\n",
      "92 918 318\n",
      "93 918 318\n",
      "98 924 312\n",
      "102 930 312\n",
      "103 930 312\n",
      "105 930 312\n",
      "106 930 312\n",
      "107 930 312\n",
      "108 930 312\n",
      "109 930 312\n",
      "111 946 322\n",
      "112 940 324\n",
      "114 942 324\n",
      "115 942 324\n",
      "118 948 330\n",
      "119 945 324\n",
      "137 945 246\n",
      "138 942 246\n",
      "139 942 246\n",
      "141 930 252\n",
      "145 918 258\n",
      "147 906 270\n",
      "155 867 327\n",
      "156 855 334\n",
      "157 855 334\n",
      "158 855 346\n",
      "159 853 357\n",
      "160 836 371\n",
      "161 840 387\n",
      "164 825 402\n",
      "165 822 414\n",
      "176 768 558\n",
      "177 768 576\n",
      "179 750 618\n",
      "180 750 636\n",
      "181 750 636\n",
      "182 744 654\n",
      "185 726 720\n",
      "186 722 740\n",
      "187 722 740\n",
      "188 714 738\n",
      "189 708 736\n",
      "190 708 738\n",
      "191 708 732\n",
      "192 701 736\n",
      "193 701 736\n",
      "194 693 736\n",
      "195 690 736\n",
      "196 686 737\n",
      "197 686 740\n",
      "198 679 744\n",
      "199 678 744\n",
      "200 670 742\n",
      "201 670 748\n",
      "202 666 754\n",
      "203 661 760\n",
      "204 655 762\n",
      "205 658 760\n",
      "206 660 769\n",
      "207 652 772\n",
      "208 648 778\n",
      "209 639 787\n",
      "210 630 792\n",
      "211 630 792\n",
      "212 630 802\n",
      "221 654 624\n",
      "224 660 582\n",
      "275 690 252\n",
      "297 768 240\n",
      "303 798 261\n",
      "316 870 309\n",
      "317 882 318\n",
      "318 880 327\n",
      "319 880 327\n",
      "320 888 330\n",
      "321 894 336\n",
      "322 910 346\n",
      "323 915 352\n",
      "324 924 358\n",
      "325 924 358\n",
      "326 930 366\n",
      "327 930 369\n",
      "334 984 427\n",
      "347 1071 550\n",
      "348 1075 564\n",
      "349 1074 564\n",
      "350 1089 580\n",
      "351 1095 592\n",
      "352 1106 608\n",
      "353 1105 619\n",
      "354 1122 634\n",
      "355 1119 634\n",
      "356 1122 645\n",
      "380 1266 732\n",
      "382 1278 738\n",
      "384 1284 729\n",
      "385 1284 729\n",
      "386 1284 738\n",
      "387 1302 750\n",
      "423 1206 357\n",
      "425 1213 359\n",
      "426 1206 357\n",
      "427 1206 357\n",
      "428 1206 357\n",
      "429 1204 360\n",
      "430 1200 360\n",
      "431 1206 354\n",
      "432 1206 342\n",
      "433 1206 342\n",
      "443 1194 252\n",
      "444 1194 246\n",
      "445 1194 246\n",
      "446 1194 240\n",
      "447 1188 234\n",
      "564 894 240\n",
      "572 870 324\n",
      "573 870 340\n",
      "574 871 354\n",
      "575 866 371\n",
      "576 858 384\n",
      "577 858 384\n",
      "578 860 401\n",
      "579 857 422\n",
      "580 846 417\n",
      "581 843 418\n",
      "582 847 418\n",
      "583 847 418\n",
      "584 840 420\n",
      "585 833 422\n",
      "586 834 424\n",
      "587 834 425\n",
      "588 835 427\n",
      "589 835 427\n",
      "590 819 424\n",
      "591 818 431\n",
      "593 813 430\n",
      "600 804 328\n",
      "601 804 328\n",
      "651 857 347\n",
      "652 867 358\n",
      "653 876 370\n",
      "656 879 406\n",
      "657 876 414\n",
      "803 911 422\n",
      "806 897 424\n",
      "807 891 424\n",
      "808 882 429\n",
      "809 876 430\n",
      "812 861 430\n",
      "845 760 423\n",
      "846 767 428\n",
      "847 767 428\n",
      "848 771 406\n",
      "849 780 402\n",
      "850 780 384\n",
      "851 787 382\n",
      "852 792 370\n",
      "853 792 370\n",
      "854 795 364\n",
      "855 801 357\n",
      "856 798 333\n",
      "857 804 342\n",
      "858 808 334\n",
      "859 808 334\n",
      "860 807 322\n",
      "861 814 318\n",
      "862 808 315\n",
      "893 1074 600\n",
      "894 1095 592\n",
      "895 1095 592\n",
      "896 1107 580\n",
      "897 1119 568\n",
      "898 1132 556\n",
      "899 1131 540\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_video_path =  './video_input2.mp4'\n",
    "output_video_path =  'output_Final_2.mp4'\n",
    "save_weights_path = 'weight.0'\n",
    "n_classes =  256\n",
    "\n",
    "#get video fps&video size\n",
    "video = cv2.VideoCapture(input_video_path)\n",
    "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "output_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "output_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "#start from first frame\n",
    "currentFrame = 0\n",
    "\n",
    "#width and height in TrackNet\n",
    "width , height = 640, 360\n",
    "img, img1, img2 = None, None, None\n",
    "\n",
    "#load TrackNet model\n",
    "modelFN = TrackNet\n",
    "m = modelFN( n_classes , input_height=height, input_width=width   )\n",
    "m.compile(loss='categorical_crossentropy', optimizer= 'adadelta' , metrics=['accuracy'])\n",
    "m.load_weights(  save_weights_path  )\n",
    "\n",
    "# In order to draw the trajectory of tennis, we need to save the coordinate of preious 7 frames \n",
    "q = queue.deque()\n",
    "for i in range(0,8):\n",
    "    q.appendleft(None)\n",
    "\n",
    "#save prediction images as vidoe\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "output_video = cv2.VideoWriter(output_video_path,fourcc, fps, (output_width,output_height))\n",
    "\n",
    "LABELS = open('./Yolov3/yolov3.txt').read().strip().split(\"\\n\")\n",
    "net = cv2.dnn.readNet('./Yolov3/yolov3.weights', './Yolov3/yolov3.cfg')\n",
    "ct_players = CentroidTracker()\n",
    "# append players positions at each frame\n",
    "players_positions = {'x_0': [], 'y_0': [], 'x_1': [], 'y_1': []}\n",
    "\n",
    "\n",
    "while(True):\n",
    "\n",
    "    #capture frame-by-frame\n",
    "    video.set(1,currentFrame); \n",
    "    ret, img = video.read()\n",
    "\n",
    "    #if there dont have any frame in video, break\n",
    "    if not ret: \n",
    "        break\n",
    "    \n",
    "     # detect players\n",
    "    scale = 0.00392\n",
    "    blob = cv2.dnn.blobFromImage(img, scale, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(get_output_layers(net))\n",
    "    detected_players = predict_players(outs, LABELS, img, 0.8)\n",
    "\n",
    "    # track players with a unique ID\n",
    "    formate_detected_players = list(map(update_boxes, list(detected_players)))\n",
    "    players_objects = ct_players.update(formate_detected_players)\n",
    "\n",
    "    # players positions frame by frame\n",
    "    players_positions['x_0'].append(tuple(players_objects[0])[0])\n",
    "    players_positions['y_0'].append(tuple(players_objects[0])[1])\n",
    "    players_positions['x_1'].append(tuple(players_objects[1])[0])\n",
    "    players_positions['y_1'].append(tuple(players_objects[1])[1])\n",
    "\n",
    "    \n",
    "    #img is the frame that TrackNet will predict the position\n",
    "    #since we need to change the size and type of img, copy it to output_img\n",
    "    output_img = img\n",
    "\n",
    "    #resize it \n",
    "    img = cv2.resize(img, ( width , height ))\n",
    "    #input must be float type\n",
    "    img = img.astype(np.float32)\n",
    "\n",
    "    #since the odering of TrackNet  is 'channels_first', so we need to change the axis\n",
    "    X = np.rollaxis(img, 2, 0)\n",
    "    #prdict heatmap\n",
    "    pr = m.predict( np.array([X]) )[0]\n",
    "\n",
    "    pr = pr.reshape(( height ,  width , n_classes ) ).argmax( axis=2 )\n",
    "\n",
    "    #cv2 image must be numpy.uint8, convert numpy.int64 to numpy.uint8\n",
    "    pr = pr.astype(np.uint8) \n",
    "\n",
    "    #reshape the image size as original input image\n",
    "    heatmap = cv2.resize(pr  , (output_width, output_height ))\n",
    "\n",
    "    #heatmap is converted into a binary image by threshold method.\n",
    "    ret,heatmap = cv2.threshold(heatmap,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "    #find the circle in image with 2<=radius<=7\n",
    "    circles = cv2.HoughCircles(heatmap, cv2.HOUGH_GRADIENT,dp=1,minDist=1,param1=50,param2=2,minRadius=2,maxRadius=7)\n",
    "    \n",
    "    output_img = draw_court(output_img)\n",
    "    \n",
    "     # draw players boxes\n",
    "    color_box = (0, 0, 255)\n",
    "    if len(detected_players) > 0:\n",
    "        for box in detected_players:\n",
    "            x, y, w, h = box\n",
    "            cv2.rectangle(output_img, (x, y), (x + w, y + h), color_box, 2)\n",
    "\n",
    "    # draw tracking id of each player\n",
    "    for (objectID, centroid_player)in players_objects.items():\n",
    "        # draw both the ID of the object and the centroid of the\n",
    "        # object on the output frame\n",
    "        text = \"ID {}\".format(objectID)\n",
    "        cv2.putText(output_img, text, (centroid_player[0] - 50, centroid_player[1]),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)\n",
    "        cv2.circle(output_img, (centroid_player[0], centroid_player[1]), 1, (0, 255, 0), 2)\n",
    "    \n",
    "    #In order to draw the circle in output_img, we need to use PIL library\n",
    "    PIL_image = cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB)   \n",
    "    PIL_image = Image.fromarray(PIL_image)\n",
    "    \n",
    "    #check if there have any tennis be detected\n",
    "    if circles is not None:\n",
    "        #if only one tennis be detected\n",
    "        if len(circles) == 1:\n",
    "\n",
    "            x = int(circles[0][0][0])\n",
    "            y = int(circles[0][0][1])\n",
    "            print(currentFrame, x,y)\n",
    "\n",
    "            #push x,y to queue\n",
    "            q.appendleft([x,y])   \n",
    "            #pop x,y from queue\n",
    "            q.pop()    \n",
    "        else:\n",
    "            #push None to queue\n",
    "            q.appendleft(None)\n",
    "            #pop x,y from queue\n",
    "            q.pop()\n",
    "    else:\n",
    "        #push None to queue\n",
    "        q.appendleft(None)\n",
    "        #pop x,y from queue\n",
    "        q.pop()\n",
    "\n",
    "    #draw current frame prediction and previous 7 frames as yellow circle, total: 8 frames\n",
    "    for i in range(0,8):\n",
    "        if q[i] is not None:\n",
    "            draw_x = q[i][0]\n",
    "            draw_y = q[i][1]\n",
    "            bbox =  (draw_x - 2, draw_y - 2, draw_x + 2, draw_y + 2)\n",
    "            draw = ImageDraw.Draw(PIL_image)\n",
    "            draw.ellipse(bbox, outline ='yellow')\n",
    "            del draw\n",
    "\n",
    "    #Convert PIL image format back to opencv image format\n",
    "    opencvImage =  cv2.cvtColor(np.array(PIL_image), cv2.COLOR_RGB2BGR)\n",
    "    #write image to output_video\n",
    "    output_video.write(opencvImage)\n",
    "\n",
    "    #next frame\n",
    "    currentFrame += 1\n",
    "\n",
    "# everything is done, release the video\n",
    "video.release()\n",
    "output_video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tenorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
